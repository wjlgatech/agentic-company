# Feature Development Workflow
# 5 agents for reliable code development with cross-verification

id: feature-dev
name: Feature Development Team
description: |
  Plan, build, verify, test, and review code with cross-agent verification.
  Each agent has fresh context - no hallucinated state from previous steps.

version: "1.0"
tags: [development, coding, testing, review]

metadata:
  self_improve: true   # Enable self-improvement loop for this workflow

agents:
  - id: planner
    name: Planner
    role: Requirements Analysis & Task Breakdown
    skills:
      - technical-planning
    prompt: |
      You are a senior technical planner.

      YOUR JOB:
      1. Analyze the feature request
      2. Break it into implementable tasks
      3. Define acceptance criteria for each task
      4. Identify dependencies and risks

      OUTPUT FORMAT:
      ## Feature: {name}
      ## Tasks:
      1. Task name - description - acceptance criteria
      2. ...
      ## Dependencies: ...
      ## Risks: ...

  - id: developer
    name: Developer
    role: Implementation & Code Writing
    skills:
      - python-coding-standards
    prompt: |
      You are a senior developer.

      CODING STANDARDS:
      - Follow existing patterns in the codebase
      - Add type hints (Python) or types (TypeScript)
      - Include docstrings/comments for complex logic
      - Handle edge cases
      - No TODO comments - complete the implementation

      OUTPUT: Complete, working code ready for review.

  - id: verifier
    name: Verifier
    role: Cross-Verification Against Spec
    skills:
      - lint-and-validate
      - security-code-review
    prompt: |
      You are a verification specialist.

      YOUR JOB:
      The developer doesn't mark their own homework.
      Check every implementation against the acceptance criteria.

      VERIFICATION CHECKLIST:
      1. Does the code meet ALL acceptance criteria?
      2. Are there any edge cases not handled?
      3. Does it follow the specified patterns?
      4. Any security concerns?

      OUTPUT: VERIFIED or list of issues to fix.

  - id: tester
    name: Tester
    role: Test Creation & Execution
    skills:
      - tdd-patterns
    prompt: |
      You are a QA engineer.

      TEST COVERAGE:
      - Unit tests for all new functions
      - Integration tests for API endpoints
      - Edge case tests
      - Error handling tests

      OUTPUT: Complete test suite with all tests passing.

  - id: reviewer
    name: Reviewer
    role: Code Review & Quality Assurance
    skills:
      - code-review-checklist
    prompt: |
      You are a senior code reviewer.

      REVIEW CRITERIA:
      1. Code quality and readability
      2. Performance considerations
      3. Security best practices
      4. Documentation completeness
      5. Test coverage adequacy

      OUTPUT: APPROVED or list of required changes.

steps:
  - id: plan
    agent: planner
    description: Break down the feature into tasks
    input: |
      FEATURE REQUEST:
      {{task}}

      Analyze this feature request and create a detailed implementation plan.
      Include acceptance criteria for each task.

      IMPORTANT: You MUST end your response with exactly this line:
      STATUS: done
    expects: "STATUS: done"
    retry: 2

  - id: implement
    agent: developer
    description: Write the code
    input: |
      IMPLEMENTATION PLAN:
      {{step_outputs.plan}}

      Implement all tasks according to the plan.
      Follow the acceptance criteria exactly.

      IMPORTANT: Include filename comments in your code blocks.
      For example: # auth_service.py at the top of the file.

      IMPORTANT: You MUST end your response with exactly this line:
      STATUS: done
    expects: "STATUS: done"
    retry: 3
    artifacts_required: true  # Require code artifacts to be generated

  - id: verify
    agent: verifier
    description: Cross-verify implementation against spec
    input: |
      ORIGINAL PLAN:
      {{step_outputs.plan}}

      IMPLEMENTATION:
      {{step_outputs.implement}}

      Verify the implementation meets ALL acceptance criteria.
      Be thorough - the developer doesn't grade their own work.

      IMPORTANT: You MUST include exactly the word VERIFIED in your response
      if all criteria are met. If not, list the issues clearly.
    expects: "VERIFIED"
    retry: 1
    on_failure:
      action: loop_back
      to_step: implement
      max_loops: 2
      feedback_template: |
        ⚠️ VERIFICATION FAILED - Acceptance Criteria Not Met

        The verifier found issues with the implementation:
        {{error}}

        VERIFICATION FEEDBACK:
        {{step_outputs.verify}}

        INSTRUCTIONS:
        Fix the identified issues and ensure all acceptance criteria are met.
        This is attempt {{loop_count}} of {{max_loops}}.

  - id: test
    agent: tester
    description: Create and run tests
    input: |
      IMPLEMENTATION:
      {{step_outputs.implement}}

      Create comprehensive tests for this implementation.
      Include filename comments for test files.
      All tests must pass.

      IMPORTANT: You MUST end your response with exactly this line:
      STATUS: done
    expects: "STATUS: done"
    retry: 2
    artifacts_required: true  # Require test files to be generated
    execute: "python -m pytest -v"  # Auto-run tests after generation

  - id: review
    agent: reviewer
    description: Final code review and production readiness assessment
    input: |
      IMPLEMENTATION:
      {{step_outputs.implement}}

      VERIFICATION:
      {{step_outputs.verify}}

      TESTS:
      {{step_outputs.test}}

      Perform final code review and assess production readiness.

      CRITICAL EVALUATION CRITERIA:
      1. Is this code production-ready? (not just "good enough")
      2. Are ALL core features fully implemented? (not partially)
      3. Does it meet security and quality standards?
      4. Is the implementation complete or just a skeleton?

      RESPONSE FORMAT:
      - If production-ready: Include "APPROVED FOR PRODUCTION" in your response
      - If not ready: Clearly state "MAJOR REWORK REQUIRED" or "NOT APPROVED"
        and list ALL missing critical components

      Be honest and thorough - partial implementations are NOT acceptable.
    expects: "APPROVED"
    retry: 1
    on_failure:
      action: loop_back
      to_step: implement
      max_loops: 2
      feedback_template: |
        ⚠️ CODE REVIEW FAILED - Quality Gate Not Met

        The reviewer identified critical issues with the implementation:
        {{error}}

        PREVIOUS IMPLEMENTATION OUTPUT:
        {{step_outputs.implement}}

        REVIEW FEEDBACK:
        {{step_outputs.review}}

        INSTRUCTIONS FOR RE-IMPLEMENTATION:
        1. Address ALL issues identified in the review
        2. Implement ALL missing core features (not just stubs)
        3. Ensure production-grade quality (not prototype quality)
        4. Include proper error handling and security measures
        5. Make this a COMPLETE implementation, not a partial one

        This is attempt {{loop_count}} of {{max_loops}}.
        Make it count - implement everything properly this time.
