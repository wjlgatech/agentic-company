{
  "run_id": "24872291",
  "artifacts": [
    {
      "type": "code",
      "filename": "main.py",
      "content": "# main.py\n\"\"\"\nAI Content Creation Multi-Agent Workflow System\nMain orchestration module for managing the entire content creation pipeline\n\"\"\"\n\nimport asyncio\nimport logging\nfrom typing import Dict, List, Optional, Any\nfrom datetime import datetime, timedelta\nfrom dataclasses import dataclass\nfrom enum import Enum\nimport json\n\nfrom agents.content_discovery import ContentDiscoveryAgent\nfrom agents.strategic_planning import StrategicPlanningAgent\nfrom agents.script_generation import ScriptGenerationAgent\nfrom agents.visual_creation import VisualContentAgent\nfrom agents.video_production import VideoProductionAgent\nfrom agents.quality_assurance import QualityAssuranceAgent\nfrom agents.publication import PublicationAgent\nfrom agents.analytics import AnalyticsAgent\nfrom interfaces.client_interface import ClientDecisionInterface\nfrom core.workflow_engine import WorkflowOrchestrationEngine\nfrom core.models import WorkflowState, ContentItem, VideoProject\nfrom core.config import Config\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nclass WorkflowStatus(Enum):\n    PENDING = \"pending\"\n    RUNNING = \"running\"\n    WAITING_CLIENT = \"waiting_client\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n\n@dataclass\nclass WorkflowResult:\n    \"\"\"Result of complete workflow execution\"\"\"\n    success: bool\n    video_url: Optional[str]\n    analytics_data: Dict[str, Any]\n    execution_time: float\n    errors: List[str]\n\nclass AIContentWorkflowSystem:\n    \"\"\"Main system orchestrator for AI content creation workflow\"\"\"\n    \n    def __init__(self, config: Config):\n        self.config = config\n        self.workflow_engine = WorkflowOrchestrationEngine(config)\n        self.client_interface = ClientDecisionInterface(config)\n        \n        # Initialize all agents\n        self.content_discovery = ContentDiscoveryAgent(config)\n        self.strategic_planning = StrategicPlanningAgent(config)\n        self.script_generation = ScriptGenerationAgent(config)\n        self.visual_creation = VisualContentAgent(config)\n        self.video_production = VideoProductionAgent(config)\n        self.quality_assurance = QualityAssuranceAgent(config)\n        self.publication = PublicationAgent(config)\n        self.analytics = AnalyticsAgent(config)\n        \n    async def run_daily_workflow(self) -> WorkflowResult:\n        \"\"\"Execute the complete daily content creation workflow\"\"\"\n        start_time = datetime.now()\n        workflow_id = f\"workflow_{start_time.strftime('%Y%m%d_%H%M%S')}\"\n        \n        try:\n            logger.info(f\"Starting workflow {workflow_id}\")\n            \n            # Step 1: Content Discovery & Curation (5 min target)\n            content_candidates = await self.content_discovery.discover_content()\n            \n            # Step 2: Strategic Content Planning (2 min target)\n            strategic_options = await self.strategic_planning.generate_strategies(content_candidates)\n            \n            # Step 3: Client Decision Point 1 - Content Selection\n            selected_content = await self.client_interface.get_content_selection(strategic_options)\n            \n            # Step 4: Script Generation (3 min target)\n            script = await self.script_generation.generate_script(selected_content)\n            \n            # Step 5: Client Decision Point 2 - Script Approval\n            approved_script = await self.client_interface.get_script_approval(script)\n            \n            # Step 6: Visual Content Creation (4 min target)\n            visuals = await self.visual_creation.create_visuals(approved_script)\n            \n            # Step 7: Video Production (15 min target)\n            video_draft = await self.video_production.produce_video(approved_script, visuals)\n            \n            # Step 8: Quality Assurance (2 min target)\n            qa_result = await self.quality_assurance.review_video(video_draft)\n            \n            # Step 9: Client Final Approval\n            if qa_result.requires_client_review:\n                final_approval = await self.client_interface.get_final_approval(video_draft, qa_result)\n                if not final_approval.approved:\n                    return WorkflowResult(False, None, {}, 0, [\"Client rejected final video\"])\n            \n            # Step 10: Publication & Distribution (3 min target)\n            publication_result = await self.publication.publish_video(video_draft)\n            \n            # Calculate execution time\n            execution_time = (datetime.now() - start_time).total_seconds() / 60\n            \n            # Start analytics tracking\n            await self.analytics.start_tracking(publication_result.video_url)\n            \n            logger.info(f\"Workflow {workflow_id} completed in {execution_time:.2f} minutes\")\n            \n            return WorkflowResult(\n                success=True,\n                video_url=publication_result.video_url,\n                analytics_data={\"workflow_id\": workflow_id, \"execution_time\": execution_time},\n                execution_time=execution_time,\n                errors=[]\n            )\n            \n        except Exception as e:\n            logger.error(f\"Workflow {workflow_id} failed: {str(e)}\")\n            return WorkflowResult(\n                success=False,\n                video_url=None,\n                analytics_data={},\n                execution_time=(datetime.now() - start_time).total_seconds() / 60,\n                errors=[str(e)]\n            )\n\nif __name__ == \"__main__\":\n    config = Config.load_from_env()\n    system = AIContentWorkflowSystem(config)\n    \n    async def main():\n        result = await system.run_daily_workflow()\n        print(f\"Workflow completed: {result.success}\")\n        if result.video_url:\n            print(f\"Video published: {result.video_url}\")\n    \n    asyncio.run(main())",
      "language": "python",
      "metadata": {
        "extracted_from": "code_block",
        "index": 0
      },
      "created_at": "2026-02-14T02:06:19.046353"
    },
    {
      "type": "code",
      "filename": "agents/content_discovery.py",
      "content": "# agents/content_discovery.py\n\"\"\"\nContent Discovery & Curation Agent\nMonitors LinkedIn, Medium, and Facebook for high-quality AI-related content\n\"\"\"\n\nimport asyncio\nimport aiohttp\nfrom typing import List, Dict, Any, Optional\nfrom datetime import datetime, timedelta\nfrom dataclasses import dataclass\nimport logging\n\nfrom core.models import ContentItem, EngagementMetrics\nfrom core.config import Config\nfrom integrations.social_platforms import LinkedInAPI, MediumAPI, FacebookAPI\n\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass CurationResult:\n    \"\"\"Result of content curation process\"\"\"\n    total_found: int\n    filtered_count: int\n    top_candidates: List[ContentItem]\n    execution_time: float\n\nclass ContentDiscoveryAgent:\n    \"\"\"Automated content discovery and curation agent\"\"\"\n    \n    def __init__(self, config: Config):\n        self.config = config\n        self.linkedin_api = LinkedInAPI(config.linkedin_credentials)\n        self.medium_api = MediumAPI(config.medium_credentials)\n        self.facebook_api = FacebookAPI(config.facebook_credentials)\n        \n        self.ai_topics = [\n            \"artificial intelligence\", \"machine learning\", \"deep learning\",\n            \"neural networks\", \"AI automation\", \"generative AI\", \"ChatGPT\",\n            \"AI tools\", \"AI productivity\", \"AI business\", \"AI future\"\n        ]\n        \n        self.relevance_threshold = 80  # Minimum relevance score\n        self.target_daily_posts = 10\n        \n    async def discover_content(self) -> List[ContentItem]:\n        \"\"\"\n        Main discovery method - finds and curates content from all platforms\n        Target: Complete within 5 minutes, find 10+ posts, filter by relevance >80%\n        \"\"\"\n        start_time = datetime.now()\n        logger.info(\"Starting content discovery process\")\n        \n        try:\n            # Parallel content discovery from all platforms\n            tasks = [\n                self._discover_linkedin_content(),\n                self._discover_medium_content(),\n                self._discover_facebook_content()\n            ]\n            \n            platform_results = await asyncio.gather(*tasks, return_exceptions=True)\n            \n            # Combine and process results\n            all_content = []\n            for result in platform_results:\n                if isinstance(result, Exception):\n                    logger.warning(f\"Platform discovery failed: {result}\")\n                    continue\n                all_content.extend(result)\n            \n            # Score and filter content\n            scored_content = await self._score_content_relevance(all_content)\n            filtered_content = [\n                item for item in scored_content \n                if item.relevance_score >= self.relevance_threshold\n            ]\n            \n            # Sort by engagement and relevance\n            top_candidates = sorted(\n                filtered_content,\n                key=lambda x: (x.relevance_score * 0.6 + x.engagement_metrics.total_score * 0.4),\n                reverse=True\n            )[:3]  # Top 3 candidates for client review\n            \n            execution_time = (datetime.now() - start_time).total_seconds() / 60\n            \n            logger.info(\n                f\"Discovery completed in {execution_time:.2f} minutes. \"\n                f\"Found {len(all_content)} posts, filtered to {len(filtered_content)}, \"\n                f\"presenting top {len(top_candidates)} candidates\"\n            )\n            \n            # Validate acceptance criteria\n            if len(all_content) < self.target_daily_posts:\n                logger.warning(f\"Only found {len(all_content)} posts, target was {self.target_daily_posts}\")\n            \n            if execution_time > 5:\n                logger.warning(f\"Discovery took {execution_time:.2f} minutes, target was 5 minutes\")\n            \n            return top_candidates\n            \n        except Exception as e:\n            logger.error(f\"Content discovery failed: {str(e)}\")\n            raise\n    \n    async def _discover_linkedin_content(self) -> List[ContentItem]:\n        \"\"\"Discover content from LinkedIn\"\"\"\n        try:\n            posts = []\n            for topic in self.ai_topics:\n                topic_posts = await self.linkedin_api.search_posts(\n                    query=topic,\n                    time_range=timedelta(days=1),\n                    min_engagement=100\n                )\n                posts.extend(topic_posts)\n            \n            return await self._convert_to_content_items(posts, \"linkedin\")\n            \n        except Exception as e:\n            logger.error(f\"LinkedIn discovery failed: {str(e)}\")\n            return []\n    \n    async def _discover_medium_content(self) -> List[ContentItem]:\n        \"\"\"Discover content from Medium\"\"\"\n        try:\n            articles = []\n            for topic in self.ai_topics:\n                topic_articles = await self.medium_api.search_articles(\n                    tag=topic,\n                    published_since=datetime.now() - timedelta(days=2),\n                    min_claps=50\n                )\n                articles.extend(topic_articles)\n            \n            return await self._convert_to_content_items(articles, \"medium\")\n            \n        except Exception as e:\n            logger.error(f\"Medium discovery failed: {str(e)}\")\n            return []\n    \n    async def _discover_facebook_content(self) -> List[ContentItem]:\n        \"\"\"Discover content from Facebook\"\"\"\n        try:\n            posts = []\n            for topic in self.ai_topics:\n                topic_posts = await self.facebook_api.search_public_posts(\n                    query=topic,\n                    time_range=timedelta(days=1),\n                    min_engagement=50\n                )\n                posts.extend(topic_posts)\n            \n            return await self._convert_to_content_items(posts, \"facebook\")\n            \n        except Exception as e:\n            logger.error(f\"Facebook discovery failed: {str(e)}\")\n            return []\n    \n    async def _convert_to_content_items(self, raw_posts: List[Dict], platform: str) -> List[ContentItem]:\n        \"\"\"Convert platform-specific posts to ContentItem objects\"\"\"\n        content_items = []\n        \n        for post in raw_posts:\n            try:\n                engagement = EngagementMetrics(\n                    likes=post.get('likes', 0),\n                    shares=post.get('shares', 0),\n                    comments=post.get('comments', 0),\n                    views=post.get('views', 0)\n                )\n                \n                content_item = ContentItem(\n                    id=f\"{platform}_{post['id']}\",\n                    title=post.get('title', '')[:100],\n                    content=post.get('content', ''),\n                    author=post.get('author', ''),\n                    platform=platform,\n                    url=post.get('url', ''),\n                    published_date=post.get('published_date', datetime.now()),\n                    engagement_metrics=engagement,\n                    relevance_score=0  # Will be calculated separately\n                )\n                \n                content_items.append(content_item)\n                \n            except Exception as e:\n                logger.warning(f\"Failed to convert post {post.get('id', 'unknown')}: {str(e)}\")\n                continue\n        \n        return content_items\n    \n    async def _score_content_relevance(self, content_items: List[ContentItem]) -> List[ContentItem]:\n        \"\"\"Score content relevance using AI analysis\"\"\"\n        from integrations.openai_client import OpenAIClient\n        \n        openai_client = OpenAIClient(self.config.openai_api_key)\n        \n        for item in content_items:\n            try:\n                # Use AI to score relevance to AI topics and content quality\n                prompt = f\"\"\"\n                Rate this content for relevance to AI/technology topics and overall quality on a scale of 0-100.\n                Consider: topic relevance, content depth, engagement potential, and educational value.\n                \n                Title: {item.title}\n                Content: {item.content[:500]}...\n                \n                Respond with just a number (0-100):\n                \"\"\"\n                \n                response = await openai_client.complete(prompt, max_tokens=10)\n                try:\n                    score = int(response.strip())\n                    item.relevance_score = min(100, max(0, score))\n                except ValueError:\n                    item.relevance_score = 50  # Default score if parsing fails\n                    \n            except Exception as e:\n                logger.warning(f\"Failed to score content {item.id}: {str(e)}\")\n                item.relevance_score = 50  # Default score\n        \n        return content_items",
      "language": "python",
      "metadata": {
        "extracted_from": "code_block",
        "index": 1
      },
      "created_at": "2026-02-14T02:06:19.046436"
    }
  ],
  "created_at": "2026-02-14T02:06:19.046454",
  "metadata": {},
  "stats": {
    "count": 2,
    "total_size_bytes": 14684,
    "total_lines": 366
  }
}